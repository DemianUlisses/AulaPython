{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zxHUgPSFM1fc"
      },
      "source": [
        "# Decision Tree\n",
        "---\n",
        "**Aula Prática 06**: Decision Tree para classificação\n",
        "\n",
        "\n",
        "**Objetivo**: Treinar um modelo de classificação utilizando árvores de decisão.\n",
        "\n",
        "**Banco de Dados**: Breast Cancer Wisconsin Dataset\n",
        "\n",
        "**Fonte**: Disponível via `sklearn`\n",
        "**Descrição**: As features são computadas a partir de uma imagem digitalizada de uma aspiração por agulha fina (FNA) de uma massa mamária. Elas descrevem as características dos núcleos celulares presentes na imagem.\n",
        "Estrutura do Dataset:\n",
        "1. ID number\n",
        "2. Diagnóstico: 0 = Maligno, 1 = Benigno\n",
        "3. Features (3-32): Dez características reais são computadas para cada núcleo celular:\n",
        "* Raio: Média das distâncias do centro aos pontos no perímetro\n",
        "* Textura: Desvio padrão dos valores de escala de cinza\n",
        "* Perímetro\n",
        "* Área\n",
        "* Suavidade: Variação local nos comprimentos dos raios\n",
        "* Compacidade: (Perímetro^2 / Área) - 1.0\n",
        "* Concavidade: Severidade das porções côncavas do contorno\n",
        "* Pontos Côncavos: Número de porções côncavas do contorno\n",
        "* Simetria\n",
        "* Dimensão Fractal: (\"Aproximação da linha costeira\" - 1)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w1NLIkJMRP4U"
      },
      "source": [
        "## Import das principais funções e leitura dos dados\n",
        "\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Wfg5H5k7QUoz"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn import datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cz13V0q4Q5ZJ"
      },
      "outputs": [],
      "source": [
        "data = datasets.load_breast_cancer()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "39H8czgiIvdT"
      },
      "outputs": [],
      "source": [
        "df = pd.DataFrame(data.data, columns=data.feature_names)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "do_VDG4RJICz"
      },
      "outputs": [],
      "source": [
        "target = pd.DataFrame(data.target, columns=['Target'])\n",
        "df = pd.concat([df, target], axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gE2hH2_8SHHZ"
      },
      "outputs": [],
      "source": [
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K94v4s0lSNC4"
      },
      "outputs": [],
      "source": [
        "df.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iyj0P08tSR5M"
      },
      "outputs": [],
      "source": [
        "df.dtypes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D4JMYa2ZJSto"
      },
      "outputs": [],
      "source": [
        "df.describe().T"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M9mSwwoqRbef"
      },
      "source": [
        "## Treino de modelo de decision tree\n",
        "---\n",
        "\n",
        "Para treinar um modelo de classificação, utilizaremos o pacote `sklearn`.\n",
        "\n",
        "\n",
        "### Separação dos Dados em Treino e Teste\n",
        "O primeiro passo para treinar um modelo é separar os dados em conjuntos de treino e teste. Para isso, utilizaremos a função `train_test_split`:\n",
        "\n",
        "``` python\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=.3, random_state=15)\n",
        "```\n",
        "* X: DataFrame contendo as features do modelo.\n",
        "* Y: DataFrame contendo a variável target.\n",
        "* test_size: Percentual de dados que será utilizado para teste (neste caso, 30%).\n",
        "* random_state: Controla a aleatoriedade da divisão dos dados, garantindo reprodutibilidade.\n",
        "\n",
        "Separar os dados em treino e teste é crucial para que possamos treinar o modelo com um conjunto de dados e avaliá-lo com outro, garantindo uma avaliação imparcial da performance do modelo.\n",
        "\n",
        "\n",
        "### Treinamento do Modelo\n",
        "Agora que já possuímos os dados de treino e teste, vamos treinar o nosso modelo de árvore de decisão:\n",
        "\n",
        "``` python\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "model = DecisionTreeClassifier()\n",
        "model.fit(X_train, Y_train)\n",
        "```\n",
        "\n",
        "No código acima, o objeto `model` é do tipo `DecisionTreeClassifier`. Ele será utilizado para ajustar o modelo, realizar predições e armazenar a árvore de decisão.\n",
        "\n",
        "Para fazer predições e acessar a importância das features, utilizamos os seguintes métodos:\n",
        "\n",
        "\n",
        "``` python\n",
        "# Para fazer predições de classes\n",
        "Y_predict = model.predict(X_test)\n",
        "\n",
        "# Para fazer predições de probabilidade\n",
        "Y_proba = model.predict_proba(X_test)\n",
        "\n",
        "# Para acessar a importância das features\n",
        "importancias = model.feature_importances_\n",
        "\n",
        "```\n",
        "\n",
        "### Parâmetros da Decision Tree\n",
        "Alguns parâmetros importantes da `DecisionTreeClassifier`:\n",
        "\n",
        "* `criterion`: Critério para quebra de um nó. Default é `gini`, mas também pode ser `entropy` e `log_loss`.\n",
        "* `max_depth`: Profundidade máxima da árvore. Default é None, o que faz com que as folhas sejam puras (observações menores que `min_samples_split`).\n",
        "* `min_samples_split`: Mínimo de amostras para separação. Default: 2.\n",
        "* `min_samples_leaf`: Mínimo de amostras em cada folha. Só será considerada quebra com no mínimo esse tamanho de amostra. Default: 1.\n",
        "* `random_state`: Semente para aleatoriedade.\n",
        "\n",
        "\n",
        "\n",
        "### Avaliação do modelo\n",
        "Para avaliar o modelo treinado, utilizaremos as métricas vistas na aula teórica:\n",
        "\n",
        "``` python\n",
        "from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score, roc_curve, RocCurveDisplay\n",
        "\n",
        "# Métricas: acurácia, precisão, recall, f1-score\n",
        "print(classification_report(Y_test, Y_predict))\n",
        "\n",
        "# Matriz de confusão\n",
        "print(confusion_matrix(Y_test, Y_predict))\n",
        "\n",
        "# AUC\n",
        "roc_auc = roc_auc_score(Y_test, Y_proba[:, 1])\n",
        "fpr, tpr, thresholds = roc_curve(Y_test, Y_proba[:, 1])\n",
        "display = RocCurveDisplay(fpr=fpr, tpr=tpr, roc_auc=roc_auc)\n",
        "display.plot()\n",
        "```\n",
        "\n",
        "\n",
        "Também é possível obter cada uma das métricas individualmente:\n",
        "``` python\n",
        "from sklearn.metrics import recall_score, precision_score, f1_score, accuracy_score\n",
        "\n",
        "\n",
        "recall = recall_score(Y_test, Y_predict, pos_label=1)\n",
        "precision = precision_score(Y_test, Y_predict, pos_label=1)\n",
        "f1 = f1_score(Y_test, Y_predict, pos_label=1)\n",
        "accuracy = accuracy_score(Y_test, Y_predict)\n",
        "```\n",
        "\n",
        "\n",
        "### Primeiro modelo\n",
        "\n",
        "---\n",
        "\n",
        "Exercício:\n",
        "1. Separe os dados em treino e teste, utilizando 30% dos dados para o conjunto de teste. Faça a divisão com todas as variáveis.\n",
        "2. Treine um modelo de árvore de decisão.\n",
        "3. Faça as análises de apuração do modelo utilizando as métricas de avaliação."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G4pgJuxgN_XX"
      },
      "outputs": [],
      "source": [
        "X = pd.DataFrame(data.data, columns=data.feature_names)\n",
        "Y = data.target"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sztPnLqBUBm4"
      },
      "source": [
        "### Exercício:\n",
        "1. Treine um novo modelo:\n",
        "* Configure o parâmetro `max_depth` para 4.\n",
        "2. Encontre o melhor limiar:\n",
        "* Busque o limiar que proporciona a melhor acurácia.\n",
        "3. Identifique a feature mais importante:\n",
        "* Determine qual feature possui a maior importância no modelo.\n",
        "\n",
        "Dica:\n",
        "Para realizar a busca do melhor limiar, siga os passos abaixo:\n",
        "1. Gere o score de probabilidade:\n",
        "* Utilize o método `predict_proba()` para obter as probabilidades preditas pelo modelo.\n",
        "* Para acessar `P(Y=1)`, utilize `predict_proba()[:, 1]`.\n",
        "2. Percorra uma lista de valores de limiar:\n",
        "* Para cada valor de limiar, calcule a acurácia.\n",
        "* Obtenha o limiar que resulta na maior acurácia."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}